'''
Created on Mar 11, 2018

@author: ashaman
'''

import logging
from analyzers.Analyst import Analyst
from beautifultable import BeautifulTable

class SelfReplicationAnalyst(Analyst):
    '''
    Checks if the specified process attempted to replicate itself
    to another process
    '''

    SELF_REPL_ANALYST_CONST = "SelfReplication Analyst"
    SELF_REPL_SUSPICIOUS_DATA_KEY_CONST = "SelfReplSuspiciousData"

    def __init__(self, processTree):
        '''
        Constructor
        '''
        self.logger = logging.getLogger('MalwareAnalyzerShell.analyzers.SelfReplicationAnalyst')

    def analyze_process(self, db_cursor, p_id):
        row = db_cursor.execute("SELECT pid, image FROM process WHERE id = %s" % p_id).fetchone()
        image = row[1]
        process_id = row[0]

        suspicion_score = 0

        if(image is None):
            # unable to determine the image of the executable and therefore
            # can't detect self-replication
            self.logger.debug("The database does not contain the required image name for process %s, unable to detect self-replication" % process_id)
            return suspicion_score

        self.logger.debug("The image name of process %s is %s" % (process_id, image))

        max_read_time = db_cursor.execute("SELECT MAX(time) FROM operation JOIN resource \
                            ON r_id = resource.id  JOIN process ON p_id = process.id WHERE process.id = %s \
                            AND type = 'F' AND op = 'READ'" % p_id).fetchone()
        max_read_time = max_read_time[0]
        if(max_read_time is None):
            #there were no reads, so I guess no self-repl possible?
            return suspicion_score


        self.logger.debug("The maximum read time for process %s is %s" % (process_id, max_read_time))

        # find all reads from the image file of the process
        reads = db_cursor.execute("SELECT data, time, r_id FROM operation JOIN resource ON r_id = resource.id \
                                    JOIN process ON p_id = process.id WHERE name = '%s' AND type = 'F' \
                                    AND op = 'READ' AND p_id = %s AND data != '0x00000000'" % (image, p_id))
        reads = reads.fetchall()

        unique_files = {}
        for index in range(0, len(reads)):
            row = reads[index]
            buffer_address = row[0]
            time_of_op = row[1]
            next_read_time = max_read_time

            self.logger.debug("Processing a read on process %s's image into buffer %s at time %s ..." % (process_id, buffer_address, time_of_op))

            # find the next time the buffer used for the read is overwritten
            next_read = db_cursor.execute("SELECT time FROM operation JOIN resource ON r_id = resource.id \
                                JOIN process ON p_id = process.id WHERE data = '%s' AND type = 'F' AND op = 'READ' AND \
                                process.id = %s AND time > %s LIMIT 1" % (buffer_address, p_id, time_of_op)).fetchone()
            if(not next_read is None):
                next_read_time = next_read[0]

            self.logger.debug("Looking for all writes to a file from buffer %s between times %s and %s"
                              % (buffer_address, time_of_op, next_read_time))

            resp = db_cursor.execute("SELECT DISTINCT operation.id, name FROM operation JOIN resource ON r_id = resource.id WHERE type = 'F' \
                                AND op='WRITE' AND data='%s' AND time > %s AND time < %s AND operation.p_id = %s" \
                                % (buffer_address, time_of_op, next_read_time, p_id)).fetchall()
#             self.logger.debug("SELECT DISTINCT operation.id, name FROM operation JOIN resource ON r_id = resource.id WHERE type = 'F' \
#                                 AND op='WRITE' AND data='%s' AND time > %s AND time < %s AND operation.p_id = %s" \
#                                 % (buffer_address, time_of_op, next_read_time, p_id))
            for row in resp:
                dest_fname = row[1]
                self.logger.debug("***Self-Replication detected:  A write was found to file %s using the specified buffer" % dest_fname)

                if dest_fname in unique_files:
                    unique_files[dest_fname][1] = row[0]
                    unique_files[dest_fname][2] += 1
                else:
                    unique_files[dest_fname] = [row[0], row[0], 1]
                    suspicion_score += 1

        for _, fInfo in unique_files.items():
            '''
            Hmm, should the score be increased for each self-replication attempt discovered, or just 1 if any self-replication
            is detected.  I'll need to think this through further ?????
            '''
            db_cursor.execute("INSERT INTO suspicious_behavior (p_id, analyst, key, value) VALUES (%s, '%s', '%s','%s|%s|%s')"
                              % (p_id, self.SELF_REPL_ANALYST_CONST, self.SELF_REPL_SUSPICIOUS_DATA_KEY_CONST, fInfo[0], fInfo[1], fInfo[2]))

        return suspicion_score

    def get_suspicious_processes(self, db_cursor):
        resp = db_cursor.execute("SELECT p_id FROM suspicious_behavior WHERE key = '%s'" %
                                 (self.SELF_REPL_SUSPICIOUS_DATA_KEY_CONST)).fetchall()
        processes = {}
        for row in resp:
            p_id = row[0]
            if p_id not in processes:
              processes[p_id] = 0

            processes[p_id] += 1

        return processes

    def get_suspicous_process_data_for_reporting(self, db_cursor, p_id):
      sus_data = []

      resp = db_cursor.execute("SELECT value FROM suspicious_behavior WHERE p_id = %s AND key = '%s'" %
                               (p_id, self.SELF_REPL_SUSPICIOUS_DATA_KEY_CONST)).fetchall()
      if len(resp):
          table = BeautifulTable(max_width=160)
          table.column_headers = ["Name", "PID", "Descriptor Addr", "First Write Time", "Last Write Time", "Number of Writes"]

          for row in resp:
              replInfo = row[0].split("|")
              first_write = db_cursor.execute("SELECT name, time FROM operation JOIN resource ON r_id = resource.id WHERE operation.id = %s" % replInfo[0]).fetchone()
              last_write = db_cursor.execute("SELECT time FROM operation JOIN resource ON r_id = resource.id WHERE operation.id = %s" % replInfo[1]).fetchone()

              procInfo = db_cursor.execute("SELECT pid, desc_address FROM process WHERE image = '%s'" % first_write[0]).fetchone()
              if procInfo is None:
                procInfo = ["", ""]

              table.append_row([first_write[0], procInfo[0], procInfo[1], first_write[1], last_write[0], replInfo[2]])


          proc = db_cursor.execute("SELECT pid, desc_address, image FROM process WHERE id = %s" % p_id).fetchone()
          sus_data.append((Analyst.DATA_TYPE_TABLE_DESCRIPTION, "Process %s %s Image:  %s\n" % (proc[0], proc[1], proc[2])))
          sus_data.append((Analyst.DATA_TYPE_TABLE_DATA, table))

      return sus_data

    def has_mit_data(self):
      return True

    def get_mit_data(self, db_cursor):
      resp = db_cursor.execute("SELECT p_id, value FROM suspicious_behavior WHERE key = '%s'" %
                               (self.SELF_REPL_SUSPICIOUS_DATA_KEY_CONST)).fetchall()
      mit_data = {}
      for row in resp:
        p_id = row[0]
        replInfo = row[1].split("|")
        imageName = db_cursor.execute("SELECT name FROM operation JOIN resource ON r_id = resource.id WHERE operation.id = %s" % replInfo[0]).fetchone()
        #self-replication occurred to the above file, check if
        #the file was used to create a process
        target_pid = db_cursor.execute("SELECT id FROM process WHERE image = '%s'" % imageName).fetchone()

        if not target_pid:
          continue

        target_pid = target_pid[0]

        if p_id not in mit_data:
          mit_data[p_id] = []

        mit_data[p_id].append((target_pid,"SR"))

      return mit_data

    def getAnalystName(self):
        return self.SELF_REPL_ANALYST_CONST

